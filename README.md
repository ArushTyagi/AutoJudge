
Important - https://autojudge-sjwz8euutbxwrogida9jg5.streamlit.app/
use this link to access the portal ... It is already deployed using streamlit

video link - https://drive.google.com/file/d/1TEWnwUciO3IGObT8NuJtxwC60jU9nue8/view?usp=sharing


üß† AutoJudge: Predicting Programming Problem Difficulty
üìå Project Overview

Online competitive programming platforms (such as Codeforces, CodeChef, and Kattis) classify problems into difficulty levels like Easy, Medium, and Hard, often assigning a numerical difficulty score.
This process usually relies on human judgment and community feedback, which can be subjective and slow.

AutoJudge is a machine learning‚Äìbased system that automatically predicts:

‚úÖ Problem Difficulty Class (Easy / Medium / Hard)

‚úÖ Problem Difficulty Score (numerical)

The prediction is based only on the textual description of the problem, without using submissions, tags, or user statistics.

The system also provides a simple web interface where users can paste a problem description and instantly receive predictions.

üìä Dataset Used

The dataset consists of programming problems stored in JSONL format

Each data sample contains:

title

description

input_description

output_description

problem_class (Easy / Medium / Hard)

problem_score (numerical difficulty)

üß† Approach & Methodology

1Ô∏è‚É£ Data Preprocessing & Noise Handling

Combined all text fields into a single input

Cleaned text (lowercasing, symbol normalization)

Removed noisy or inconsistent samples

Handled missing values safely


2Ô∏è‚É£ Feature Engineering (Text-Only)

A rich hybrid feature set was designed to make the project stand out:

Text-based features

Word-level TF-IDF

Character-level TF-IDF

Handcrafted linguistic & cognitive features

Text length and lexical entropy

Keyword counts (e.g., graph, dp, recursion)

Algorithmic intent indicators

Cognitive load estimation

Constraint pressure (based on numeric limits)

Input grammar complexity

Failure-awareness signals (warnings, edge cases)


3Ô∏è‚É£ Classification Models (Difficulty Class)

The following models were trained and compared:

Logistic Regression

Linear SVM

RBF SVM

Random Forest Classifier

Ordinal Classifier was used with the best model

‚úî Ordinal classification respects the natural ordering:

Easy < Medium < Hard

Ordinal Classification Report:

                  precision recall f1-score   support

        Easy       0.45      0.42      0.44       121
        Hard       0.58      0.79      0.67       388
      Medium        0.42      0.23      0.30       281

    accuracy                            0.53       790
   macro avg       0.48      0.48      0.47       790
weighted avg       0.51      0.53      0.50       790





4Ô∏è‚É£ Regression Models (Difficulty Score)

The following regressors were trained and compared:

Linear Regression

ElasticNet

Huber Regressor

Random Forest Regressor

Gradient Boosting Regressor

‚úî The best regressor is selected based on MAE (Mean Absolute Error).
GradientBoostingRegressor(best model)
   MAE  = 1.6736
   RMSE = 1.9792
   R¬≤   = 0.1237



üìà Evaluation Metrics
Classification

Accuracy

Balanced Accuracy

Precision / Recall / F1-score

Regression

MAE (Mean Absolute Error)

RMSE (Root Mean Squared Error)

R¬≤ Score

Baseline comparisons are used to ensure meaningful improvement.



üåê Web Interface

A simple and lightweight Streamlit web application is provided.

Features:

Text boxes for:

Problem description

Input description

Output description

A Predict button

Displays:

Predicted difficulty class

Predicted difficulty score

‚úî No authentication
‚úî No database
‚úî Uses the same trained models and preprocessing pipeline

‚ñ∂Ô∏è Steps to Run the Project Locally
1Ô∏è‚É£ Clone the Repository
git clone https://github.com/<your-username>/AutoJudge.git
cd AutoJudge

2Ô∏è‚É£ Create and Activate Virtual Environment
python -m venv venv
venv\Scripts\activate   # On Windows

3Ô∏è‚É£ Install Dependencies
pip install -r requirements.txt

python -m training.classifier_compare

python -m training.regressor_compare


4Ô∏è‚É£ Run the Web Interface
streamlit run ui/app.py


The app will open automatically in your browser.

üé• Demo Video

üìΩÔ∏è Demo Video (2‚Äì3 minutes):
üëâ Add your demo video link here
(e.g., Google Drive / YouTube unlisted link)

üë§ Author Details

Name: Arush Tyagi
Project Type: Machine Learning / Data Science
Institution: IIT Roorkee


